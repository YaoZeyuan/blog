---
title: ChatGPT 快问快答
tags: 人工智能
date: 2023-02-18 13:00:00
---

> 十个问题快速了解 ChatGPT

## Q0: ChatGPT 有智慧吗

受制于基础理论限制, ChatGPT 并不理解它在说什么, 也谈不上智慧.

以下来自 ChatGPT 的自我介绍

> ChatGPT 是一种**大型语言模型**，由 OpenAI 开发。它被训练来生成文本，可以像人类一样进行对话。ChatGPT 可以根据上下文理解语境，并**生成合理的回答或接下来的句子**。这种技术的应用包括自动客服，问答系统，文本生成等。ChatGPT 是一种基于 transformer 架构的语言模型，在 transformer 架构上进行了优化，能够处理大量文本数据，并快速生成文本。总之，ChatGPT 是一种深度学习技术，能够**通过训练文本数据来模拟人类语言的行为**。

划重点:

1.  是**大型语言模型**而非**通用智能模型**
2.  专长是根据上下文**生成合理回答或者下文**

重点是生成**合理**的回答而非**正确**的回答. 至于为什么不能生成正确的回答, 请见**重点一**

## Q1: 虽然 ChatGPT 的回答并不总是正确, 但为什么它有些回答可以答对, 有些回答虽然答错, 但看起来只是细节错误, 思路却很清晰

ChatGPT 通过前期训练, 从网络文献中中获得了两个能力: 回答问题的模板(思路)和拿来嵌入模板的名词库.

当收到用户提问时, 它会选择一份合适的回答模板(思路), 然后从名词库中找到对应名词填充进去.

这样当它匹配到正确思路时, 它的回答有两种可能:

1. 思路正确, 填充的名词也正确 => 对应于回答正确的场景, 让人印象深刻
2. 思路正确, 填充的名词不正确 => 对应于思路正确但细节有问题. 由于人类评判回答准确性时往往是先看思路是否正确, 略过对具体细节的查证. 这种情况下, ChatGPT 正好 hack 了人类的评价系统, 所以会给人一种: 它其实了解这方面的知识, 只是细节有问题的错觉

## Q2: ChatGPT 回答的真相是什么

ChatGPT 通过训练, 获得了文本间的统计学规律.

例如: 当中国人说`宫廷玉液酒`, 下文有 80%的可能是`一百八一杯`, 有 20%的可能是`你想说什么`. ChatGPT 发现这个规律后, 会返回他认为概率最大的文本对提问内容进行补全. 这中间涉及了非常复杂的数学和统计学运算, 但最终结果是一样的: 大部分场景下, ChatGPT 可以补全出合理的文本

还记得第一个问题里 ChatGPT 对自己的介绍吗

> ...ChatGPT 可以根据上下文理解语境，并**生成合理的回答或接下来的句子**...

## Q3: 但我还是不能理解, 为什么 ChatGPT 拥有这么强的学习能力, 却做不对三位数的加减法

因为 ChatGPT 获得的是文本间的统计学规律, 而非数学规律, 它并不具备数理逻辑的泛化能力

对文本间统计学规律而言, ChatGPT 在学习时看到了很多类似于 `1 + 1 = 2`这样的文本, 所以当我们提问`1 + 1 = ?`时, 它可以正确的续写出`2`. 但对于不常见的文本, 例如`82767 + 33251 = ?`, 由于正常文本中不会出现这种数字, 所以 ChatGPT 不知道后边应该补全什么内容, 所以会开始瞎猜----在人类看来就是会给一个错误的回答.

毕竟, **它只是补全对话, 但并不理解**

## Q4: 虽然但是, 即使它有那么多不足, 但能把人机交互的体验从**难以忍受**提升到**偶有惊喜**, 也很优秀了, 对吗

是的. 事实上, 即使只有 30%的可能能帮我们解决问题, 那也是一个非常值得尝试的工具----何况 ChatGPT 对解决问题的有效率远不止 30%

ChatGPT 可以帮我们写很多很多的套路稿, 陪我们做咨询, 帮我们节约大把时间----只盯着它不会做三位数加减法去黑, 就有点因小失大了.

## Q5: ChatGPT 这么有用, 商业价值也很大吧

并不是, 主要局限于三个方面:

1.  无法保证正确, 甚至可控. 对商业应用而言, 我们会期望提供的服务是`正确的`, 或者至少是`可控的`. 作为中国移动老板, 或许可以接受 ChatGPT 报错套餐价格, 但如果 ChatGPT 在某次回答时推荐客户购买联通套餐, 这就无法忍受了. 然而由于 ChatGPT 只是语言模型, 它并不理解它在说什么, 所以无法保证`正确`, 同时, 由于训练过程本身是黑盒, 没有人可以保证 ChatGPT 不会答出某些内容, 所以`可控性`也无法保证.
2.  无法灌输新知识. ChatGPT 的知识是在训练时固化到模型中的, 训练完成后无法对其知识进行修正. 考虑到 GPT-3 模型单次训练成本 450 万美元, 大约 3000 万人民币, 这意味着训练完成后不可能进行新的训练, 因此一旦知识发生改变(例如售价变更, 流程变更), ChatGPT 的回答就会出错. 进而导致无法商用.
3.  没有私有化部署服务. 这个属于 OpenAI 公司本身的规则. 但由于不能进行私有化部署, 而大公司的内部知识往往涉密无法传递出去, 导致 ChatGPT 无法使用公司内部知识进行训练, 从而限制 ChatGPT 的应用范围.

## Q6: ChatGPT 无法接受任何新知识吗?

严格意义上说也不是. ChatGPT 支持在对话前添加一段引导语(prompt)对对话场景进行设定, 引导语中的内容可以作为新知识存在于对话中.

主要问题是: 引导语最大不能超过 4000 字(token)

## Q7: ChatGPT 可以记住对话的上下文, 虽然引导语不能超过 4000 字, 但能否通过持续对话的方式, 将新知识注入进对话中

也不可以. 因为 ChatGPT 记住上下文的方式, 就是将上下文内容放在引导语(prompt)中.

可以通过一个方法快速验证这点:

1.  正常聊天, 然后冷不丁问一句: 我上上句话问的什么----可以答出
2.  正常聊天, 先贴两篇 4000 字以上的文章再问我上上句话问的什么----ChatGPT 就会开始编造模式...

## Q8: 好吧, 所以你认为 ChatGPT 的意义在哪里

ChatGPT 最大的意义在于: 它为我们指明了未来的样子.

虽然 ChatGPT 无法商用, 但他证明了这条路可以走通. ChatGPT 本身的原理并不复杂, 相关研究论文也很多, 复现只是时间问题.

可以想象, 未来一定会有三个以上的同类模型出现, 而只要有一个模型能够解决之前讨论的限制, 这类 XX@GPT 就可以用于商用从而大规模改变现状.

## Q9: 所以, ChatGPT 是创新吗, 它属于哪种创新

- 是应用层创新, 而不是基础理论突破. 目前 XX@GPT 算法的本质都是**复读与模仿**, **没有思考与逻辑**
- 应用层创新指什么
  - iPhone 出现时, 智能手机相关的技术均已成熟(摄像头/传感器/移动操作系统/...), iPhone 的意义在于将已有技术整合为一, 提供了全新的体验
  - 区块链技术/加密货币出现时, 相关的密码学理论均已成熟, 区块链是基于密码学原理实现的应用, 而非在密码学上有所突破
- 基础理论突破会是什么
  - AI 领域: `深度学习模型`能够解释为何模型是有效的
  - 认知科学领域: 人脑研究取得突破, `思考`的本质得到确认

## Q10: 最后一个问题: 你说的这些都是概括, 有针对具体细节的科普吗

有的. 我整理了一下, 有兴趣可以点链接查看

---

### 非技术视角看 ChatGPT

1.  最近很火的 ChatGPT 究竟是什么？会给我们的生活带来什么改变？: https://mp.weixin.qq.com/s/GkUPpftkv5fS6qHMZm8ZuA

### 业务/应用场景分析

1.  潘一鸣: AIGC 风口，人工智能又又又行了吗: https://mp.weixin.qq.com/s/HrFrUgrDyGRYphwbgpHvvg
2.  潘一鸣: AIGC 距离 iPhone 时刻还有多久: https://mp.weixin.qq.com/s/iDM7DkhTytOsnGLWLV9Xtg
3.  聊聊 ChatGPT: https://www.ateasthillside.com/p/1-chatgpt

### 原理解析/科普

以下两篇文章均是解释了神经网络的统计学模型本质. 第一篇作者是`Stephen Wolfram`, 非常详尽但不一定通俗. 第二篇是简单科普, 可以作为入门平替

1. 万字长文解释 ChatGPT 在做什么，以及为什么它能发挥作用？: https://mp.weixin.qq.com/s/ynP5gBSv4nQXpX8vEChUUg
2. ChatGPT 背后的 OpenAI 是家怎样的公司: https://www.zhihu.com/question/583348944/answer/2891376088

### 原理解析/论文综述

1.  LLM 是什么: https://www.mittrchina.com/news/detail/10993
2.  大型语言模型系列解读（一)：大语言模型涌现的新能力 : https://zhuanlan.zhihu.com/p/601360789
3.  大型语言模型系列解读（二)：Transformer 中 FFN 的记忆功能: https://zhuanlan.zhihu.com/p/604739354
4.  拆解追溯 GPT-3.5 各项能力的起源: https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756#cf00f4e11d974187956122ce7d534386
5.  深入理解语言模型的突现能力: https://yaofu.notion.site/514f4e63918749398a1a8a4c660e0d5b

### 哲学探讨/原理限制

1.  中文屋子思想实验: https://baike.baidu.com/item/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4/3581768
2.  鸭子测试: 如果它看起来像鸭子、游泳像鸭子、叫声像鸭子，那么它可能就是只鸭子。 https://zh.wikipedia.org/zh-hans/%E9%B8%AD%E5%AD%90%E6%B5%8B%E8%AF%95
3.  过于高深的科技都宛如神迹, 然而基础理论决定应用能力上限
    > 成吉思汗的骑兵，攻击速度与 20 世纪的装甲部队相当；北宋的床弩，射程达一千五百米，与 20 世纪的狙击步枪差不多；但这些仍不过是古代的骑兵与弓弩而已，不可能与现代力量抗衡.
    >
    > via 三体 2:黑暗森林
4.  基础理论方面:
    1.  认知科学仍然在发展中
    2.  人工智能基础理论近期未有突破
